{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Level LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn import datasets, metrics, cross_validation\n",
    "from urllib import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "URL = \"https://github.com/anucc/metatone-analysis/raw/master/metadata/\"\n",
    "PICKLE_FILE = \"metatone_performances_dataframe.pickle\"\n",
    "\n",
    "if not os.path.exists(PICKLE_FILE):\n",
    "    urlretrieve(URL + PICKLE_FILE, PICKLE_FILE)\n",
    "\n",
    "with open(PICKLE_FILE, 'rb') as f:\n",
    "        metatone_dataset = pickle.load(f)\n",
    "        \n",
    "## Int values for Gesture codes.\n",
    "NUMBER_GESTURES = 9\n",
    "GESTURE_CODES = {\n",
    "    'N': 0,\n",
    "    'FT': 1,\n",
    "    'ST': 2,\n",
    "    'FS': 3,\n",
    "    'FSA': 4,\n",
    "    'VSS': 5,\n",
    "    'BS': 6,\n",
    "    'SS': 7,\n",
    "    'C': 8}\n",
    "\n",
    "vocabulary_size = len(GESTURE_CODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Isolate the Interesting Performances\n",
    "improvisations = metatone_dataset[\n",
    "    (metatone_dataset[\"performance_type\"] == \"improvisation\") &\n",
    "    (metatone_dataset[\"performance_context\"] != \"demonstration\") &\n",
    "    (metatone_dataset[\"number_performers\"] == 4)]\n",
    "gesture_data = improvisations['gestures']\n",
    "#metatone_dataset[\"number_performers\"]\n",
    "ensemble_improvisations = gesture_data.tolist()\n",
    "\n",
    "## Setup the epochs\n",
    "## Each batch is of single gestures as input and tuples of remaining performers as output\n",
    "def generate_epochs(num_epochs, num_steps, batch_size):\n",
    "    ## Setup the inputs and label sets\n",
    "    imp_xs = []\n",
    "    imp_ys = []\n",
    "    \n",
    "    for imp in ensemble_improvisations:\n",
    "        for i in range(len(imp)-num_steps):\n",
    "            imp_slice = imp[i:i+num_steps]\n",
    "            for j in range(len(imp_slice.T)):\n",
    "                imp_x = imp_slice.T[j] # just one input gesture\n",
    "                imp_y = imp_slice.T[np.arange(len(imp_slice.T)) != j] # indexed by player\n",
    "                imp_y = imp_y.T # back to indexed by time slice\n",
    "                imp_xs.append(imp_x)\n",
    "                imp_ys.append(imp_y)\n",
    "    \n",
    "    dataset = zip(imp_xs,imp_ys)\n",
    "    print(\"Total Training Examples: \" + str(len(imp_xs)))\n",
    "    print(\"Total Training Labels: \" + str(len(imp_ys)))\n",
    "    epochs = []\n",
    "    for j in range(num_epochs):\n",
    "        # shutffle the big list\n",
    "        np.random.shuffle(dataset)\n",
    "        dataset_size = len(dataset)\n",
    "        batches = []\n",
    "        for i in range(dataset_size / batch_size):\n",
    "            ## Setup the batches\n",
    "            batch = dataset[i*batch_size:(i+1)*batch_size]\n",
    "            bx,by = zip(*batch)\n",
    "            batches.append((np.array(bx),np.array(by)))\n",
    "        epochs.append(batches)\n",
    "    return epochs\n",
    "\n",
    "\n",
    "#t = ensemble_improvisations[0]\n",
    "#len(t[0])\n",
    "#t.T[np.arange(len(t.T))!=0]\n",
    "#np.arange(len(t))!=3\n",
    "\n",
    "# Test \n",
    "#a = generate_epochs(2,10,20)\n",
    "#e1 = a[0]\n",
    "#e2 = a[1]\n",
    "#print(len(e1))\n",
    "#print(len(e2))\n",
    "#print(e1[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "## Training Network\n",
    "## Hyperparameters for training\n",
    "num_nodes = 64\n",
    "num_classes = vocabulary_size\n",
    "batch_size = 64\n",
    "num_steps = 120\n",
    "num_layers = 3\n",
    "learning_rate = 1e-4\n",
    "\n",
    "def load_graph():\n",
    "    #graph = tf.Graph()\n",
    "    reset_graph()\n",
    "    graph = tf.get_default_graph()\n",
    "    with graph.as_default():\n",
    "        x = tf.placeholder(tf.int32,[batch_size,num_steps], name='input_placeholder')\n",
    "        y = tf.placeholder(tf.int32,[batch_size,num_steps], name='labels_placeholder')\n",
    "        embeddings = tf.get_variable('embedding_matrix', [num_classes, num_nodes])\n",
    "        rnn_inputs = tf.nn.embedding_lookup(embeddings,x)\n",
    "\n",
    "        # Define the network\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(num_nodes,state_is_tuple=True)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)\n",
    "        init_state = cell.zero_state(batch_size,tf.float32)\n",
    "        rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "        with tf.variable_scope('softmax'):\n",
    "            W = tf.get_variable('W',[num_nodes,num_classes])\n",
    "            b = tf.get_variable('b',[num_classes], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        rnn_outputs = tf.reshape(rnn_outputs,[-1,num_nodes])\n",
    "        y_reshaped = tf.reshape(y,[-1])\n",
    "\n",
    "        logits = tf.matmul(rnn_outputs, W) + b\n",
    "        predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y_reshaped))\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "## Training Network\n",
    "## Hyperparameters for training\n",
    "num_nodes = 64\n",
    "num_classes = vocabulary_size\n",
    "batch_size = 64\n",
    "num_steps = 120\n",
    "num_layers = 3\n",
    "learning_rate = 1e-4\n",
    "\n",
    "load_graph()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
